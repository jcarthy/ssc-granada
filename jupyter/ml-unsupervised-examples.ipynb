{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements to Run\n",
    "\n",
    "Please see the notebook ml-supervised-exersises for the requirements to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import KMeans\n",
    "from umap import UMAP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.cm as colormap\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data should be split into train and test sets using the script in the bin directory before running this notebook.\n",
    "\n",
    "When training different models it is important to keep a seperate test set that is not used for training. This is to ensure that the model is not overfitting to the training data. The test set should only be used to evaluate the final model. The test set should not be used to tune the model. If the model is tuned using the test set then the model will not generalise well to unseen data.\n",
    "\n",
    "In the supervised task, it is important to have a seperate validation and test set to prevent it overfitting to the known labels.\n",
    "\n",
    "For the unsupervised task, in certain cases it may not be wise to perform a train-test split. For example, if the goal is to cluster a fixed dataset, then the test set is not required as we are only interested in relationships within the current dataset. If the goal is to cluster data that is continually being collected, then a test set is required to evaluate the expected performance of the model on unseen data.\n",
    "\n",
    "In this notebook, we assume we want methods that have the potential to generalise and so we will split the data into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the data type by changing the path\n",
    "# 3 Options by default: raw, raw-fft-split-1, raw-fft-split-2\n",
    "# raw: time series data, 6000 samples, 100 Hz, padded\n",
    "# raw-fft-split-1: Absolute of FFT of unpadded time series data, 512 bins\n",
    "# raw-fft-split-3: Split FFT into 3 Sections in Time: Absolute of FFT of each time series chunk: 512 bins per chunk\n",
    "\n",
    "train_data = np.load(\"../datasets/llaima/raw-fft-split-3/train_data.npy\")\n",
    "train_labels = np.load(\"../datasets/llaima/train_labels.npy\")\n",
    "\n",
    "val_data = np.load(\"../datasets/llaima/raw-fft-split-3/val_data.npy\")\n",
    "val_labels = np.load(\"../datasets/llaima/val_labels.npy\")\n",
    "\n",
    "test_data = np.load(\"../datasets/llaima/raw-fft-split-3/test_data.npy\")\n",
    "test_labels = np.load(\"../datasets/llaima/test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we ensure that the data is in the correct format for the models\n",
    "# Note that we reshape the data to be 1D arrays\n",
    "# This only affects the case where we have split in time and computed the FFT on multiple segments\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n",
    "val_data = val_data.reshape(val_data.shape[0], -1)\n",
    "test_data = test_data.reshape(test_data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine our train and validation sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    0: \"LP\",\n",
    "    1: \"TC\",\n",
    "    2: \"TR\",\n",
    "    3: \"VT\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the data look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 3 \n",
    "fig, ax = plt.subplots(grid_size, grid_size, figsize=(7, 7))\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        ax[i][j].plot(train_data[i * 5 + j])\n",
    "        ax[i][j].set_title(label_dict[train_labels[i * 5 + j]])\n",
    "fig.suptitle(\"Sample Events\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Clustering is a common type of unsupervised learning method that aims to group similar instances together without the need for any labels. An example of this with 2D data is shown below (credit Datacamp, https://www.datacamp.com/tutorial/k-means-clustering-python)\n",
    "\n",
    "A common clustering method is K means clustering. This method aims to find a fixed number of clusters in the data. The number of clusters is a hyperparameter that needs to be set before training the model. The number of clusters can be set by the user or can be found using a search method such as grid search.\n",
    "\n",
    "The K means algorithm works by randomly assigning each instance to a cluster. Then the mean of each cluster is calculated. The instances are then reassigned to the cluster with the closest mean. This process is repeated until the clusters no longer change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='images/kmeans.png', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans(n_clusters=4, random_state=0)\n",
    "\n",
    "train_preds = kmeans_model.fit_predict(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we evaluate the performance of this? Computing the accuracy directly does not seem wise... It would be nice to visualise the clusters instead. To do this, we can use dimensionality reduction techniques such as UMAP to reduce the data to 2 dimensions and then plot the clusters. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_reducer = UMAP(n_components=2)\n",
    "reduced_data = dimension_reducer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"x\": reduced_data[:, 0], \"y\": reduced_data[:, 1], \"label\": train_labels, \"pred\": train_preds})\n",
    "df.label = df.label.map(label_dict)\n",
    "df.pred = df.pred.map(label_dict)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"label\", style=\"pred\", palette=\"tab10\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that the method is capturing the data and that there is a relationship between the clusters obtained and the labels, however the quality is not clear. A useful metric for evaluating the similarity between the labels and the predictions is the adjusted rand index. This metric has an upper bound of 1, and 0 indicates pure randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_score = adjusted_rand_score(train_labels, train_preds)\n",
    "\n",
    "print(\"Rand Score: \", rand_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many methods to try and improve this score. A simple way could be to attempt to cluster the data using different numbers of clusters. An alternative would be to cluster the data based on a reduced number of dimensions. This could be done by using a dimensionality reduction technique such as PCA or UMAP. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal is to simplify the problem however there is no need to reduce the dimensionality of the data to 2D for clustering.\n",
    "\n",
    "# There are arguments regarding the use of UMAP for clustering - do so with caution!\n",
    "# https://umap-learn.readthedocs.io/en/latest/clustering.html\n",
    "dimension_reducer2 = UMAP(n_components=10, min_dist=0)\n",
    "not_so_reduced_data = dimension_reducer.fit_transform(train_data)\n",
    "\n",
    "kmeans_model2 = KMeans(n_clusters=4, random_state=0)\n",
    "train_preds2 = kmeans_model2.fit_predict(not_so_reduced_data)\n",
    "\n",
    "rand_score2 = adjusted_rand_score(train_labels, train_preds2)\n",
    "\n",
    "print(\"Rand Score: \", rand_score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight increase in performance when training on reduced data, however not a significant improvement. For unsupervised methods, the feature extraction and the feature engineering phases of the process are very important. By transforming the data into a more suitable representation, the performance of the model could potentially be improved. Additionally methods using autoencoders or other neural networks could be used to learn a more suitable representation of the data.\n",
    "\n",
    "Potentially a different clustering method could also give better results! K means is the baseline method and is a good starting point, however there are many other methods that could be tried. A starting point is to try different clustering methods that are available in scikit-learn (https://scikit-learn.org/stable/modules/clustering.html). Different methods will have the potential to perform better on different types of data. It is important to try different methods and see which works best for the data at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='images/cluster-comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssc-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
